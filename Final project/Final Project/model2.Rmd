---
title: "Untitled"
author: "Jay Zhu"
date: "2022-12-06"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Model 2 - DNN
```{r}
# Helper packages
library(tensorflow)
library(keras)
library(caret)
library(plyr)
```

## Import data
```{r}
radio_df <- read.csv("radiomics_completedata.csv")
radio_df$Institution <- revalue(radio_df$Institution, c(A = "1", B = "2", C="3", D="4"))
```

## Split dataset
```{r}
# Set seeds
seeds = set.seed(200)

#splitting the data into training and testing
index<-createDataPartition(radio_df$Failure.binary,p=0.7,list=F)

#Test labels in the Species column (column 5)
Train_Features <- data.matrix(radio_df[index,-2])
Train_Labels <- radio_df[index,2]

Train_Labels

Test_Features <- data.matrix(radio_df[-index,-2])
Test_Labels <- radio_df[-index,2]
Test_Labels
# Converting the labels into categorical
to_categorical(as.numeric(Train_Labels))[,c(-1)] -> Train_Labels
to_categorical(as.numeric(Test_Labels))[,c(-1)] -> Test_Labels
```


## Data structure
```{r}
#Structure the dataaset
str(Train_Features)
```

## Create the matrix
```{r}
#converting the features into matrix
as.matrix(apply(Train_Features, 2, function(x) (x-min(x))/(max(x) - min(x)))) -> Train_Features
as.matrix(apply(Test_Features, 2, function(x) (x-min(x))/(max(x) - min(x)))) -> Test_Features
```

## Create the model
```{r}
#model training
model <- keras_model_sequential() %>%
  layer_dense(units = 256, activation = "sigmoid", input_shape= ncol(Train_Features)) %>%
  layer_dropout(rate = 0.25) %>% 
  layer_dense(units = 128, activation = "sigmoid") %>%
  layer_dropout(rate = 0.25) %>% 
  layer_dense(units = 128, activation = "sigmoid") %>%
  layer_dropout(rate = 0.25) %>% 
  layer_dense(units = 64, activation = "sigmoid") %>%
  layer_dropout(rate = 0.25) %>%
  layer_dense(units = 64, activation = "sigmoid") %>%
  layer_dropout(rate = 0.25) %>%
  layer_dense(units = 2, activation = "softmax") %>%

  compile(
    loss = "sparse_categorical_crossentropy",
    optimizer = optimizer_rmsprop(),
    metrics = c('accuracy')
  )
  
summary(model)
```

## Model compiling
```{r}
model %>% compile(
  loss = "sparse_categorical_crossentropy",
  optimizer = optimizer_adam(),
  metrics = c("accuracy")
)
```

#trained model history
```{r}
history <- model %>% 
  fit(Train_Features, Train_Labels, epochs = 50, batch_size = 128, validation_split = 0.15)

plot(history)
```


#model evaluation
```{r}
model %>%
  evaluate(Test_Features, Test_Labels)
```


#model prediction
```{r}
model %>% predict(Test_Features)
```








